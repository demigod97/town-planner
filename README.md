# ğŸ™ï¸ Town Planner RAG System

A **multiâ€‘LLM, retrievalâ€‘augmented generation (RAG)** platform for townâ€‘planning professionals. Upload planning documents (PDF/DOCX), extract structured data & metadata, ask contextual questions, and autoâ€‘generate professional reports.

---

## âœ¨ Key Features

| Area                     | Highlights                                                                                                |
| ------------------------ | --------------------------------------------------------------------------------------------------------- |
| **Document Ingestion**   | â€¢ LlamaCloud OCR + markdown parsing  â€¢ AI metadata discovery  â€¢ Semantic chunking with table preservation |
| **Vector Search**        | Postgres **`vector`** extension + `chunk_embeddings` table for fast cosine similarity via `ivfflat` index |
| **Multiâ€‘LLM**            | Ollama (local), OpenAI, Gemini, LlamaCloud â€“ switch per request; unified config via `LLM_DEFAULTS`        |
| **Report Engine**        | Edge functions generate section queries, batch vector search, and draft content into **Markdown / DOCX**  |
| **Realtime Workflows**   | n8n webhooks orchestrate chat, embedding jobs, and status updates                                         |
| **Secure, Multiâ€‘Tenant** | Supabase Auth + RLS on every table; perâ€‘user storage buckets                                              |

---

## ğŸ—ï¸ Highâ€‘Level Architecture

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend    â”‚â”€â”€filesâ”€â”€â–¶â”‚  Supabase      â”‚â”€â”€trigâ”€â”€â–¶ Edge Functions â”‚
â”‚  (Svelte/TS) â”‚  REST    â”‚  (DB + Storage)â”‚        â”‚  (Deno)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–² WebSockets/HTTP              â”‚ REST (RLS)                â”‚ Webhooks
       â”‚                              â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    n8n        â”‚  â†â€”â€”â€”chatâ€” â”‚   LLMs        â”‚  embed  â”‚  Ollama /      â”‚
â”‚ (Workflow)    â”‚            â”‚ (Ollama/API) â”‚ â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚  OpenAI/Gemini â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Repository Structure

```
â”œâ”€ supabase/
â”‚  â”œâ”€ migrations/              # SQL schema (see v2.0)
â”‚  â”œâ”€ functions/
â”‚  â”‚   â”œâ”€ process-pdf-with-metadata/
â”‚  â”‚   â”œâ”€ generate-embeddings/
â”‚  â”‚   â”œâ”€ batch-vector-search/
â”‚  â”‚   â”œâ”€ generate-report/
â”‚  â”‚   â””â”€ process-report-sections/
â”œâ”€ src/
â”‚  â”œâ”€ lib/
â”‚  â”‚   â”œâ”€ api.ts               # Supabase client + helper SDK
â”‚  â”‚   â”œâ”€ llm-config.ts        # LLM provider defaults
â”‚  â”‚   â””â”€ compatibility/       # apiâ€‘compatibility-functions.ts
â”‚  â”œâ”€ components/              # UI components (ChatStream, SourcesSidebar â€¦)
â”œâ”€ n8n-workflows.json          # Import into n8n
â”œâ”€ deployment-setup-script.sh  # Oneâ€‘click local install
â””â”€ README.md
```

---

## ğŸ”§ Database Overview (SupabaseÂ Postgres v2.0)

<table>
<tr><th>Category</th><th>Tables</th><th>Purpose</th></tr>
<tr><td>Auth / Profiles</td><td><code>user_profiles</code></td><td>Extends <code>auth.users</code> with preferences</td></tr>
<tr><td>Projects</td><td><code>notebooks</code> Â· <code>sources</code></td><td>Group documents + upload tracking</td></tr>
<tr><td>Metadata</td><td><code>metadata_schema</code> Â· <code>pdf_metadata</code> Â· <code>pdf_metadata_values</code></td><td>AI field discovery & validation</td></tr>
<tr><td>RAG</td><td><code>document_chunks</code> Â· <code>chunk_embeddings</code> Â· <code>chunk_metadata_associations</code></td><td>Semantic search corpus</td></tr>
<tr><td>Chat</td><td><code>chat_sessions</code> Â· <code>chat_messages</code></td><td>Conversation history & token usage</td></tr>
<tr><td>Reports</td><td><code>report_templates</code> Â· <code>report_generations</code> Â· <code>report_sections</code></td><td>Templated report pipeline</td></tr>
<tr><td>Jobs</td><td><code>processing_jobs</code></td><td>Background workflow status</td></tr>
</table>

**Key indexes & helpers**

* `idx_embeddings_vector` â€” vector cosine IVFFLAT
* `match_embeddings(query_embedding)` â€” serverâ€‘side similarity SQL function
* `v_document_stats`, `v_active_jobs` â€” monitoring views

Rowâ€‘level security (RLS) enabled on every table; policies mirror `user_id` ownership.

---

## ğŸ”Œ Edge Functions (Deno)

| Function                      | Description                                                                                                             |
| ----------------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| **process-pdf-with-metadata** | Parses PDF via LlamaCloud â†’ discovers metadata â†’ semantic chunking â†’ inserts chunks & kicks **generateâ€‘embeddings** job |
| **generate-embeddings**       | Batch embeds chunks using Ollama/OpenAI/Gemini embedding endpoints                                                      |
| **batch-vector-search**       | Accepts multiple queries, returns topâ€‘k matches with similarity scores                                                  |
| **generate-report**           | Creates `report_generations` record & initial `report_sections` queries                                                 |
| **process-report-sections**   | Iterates sections â†’ searches context â†’ drafts content with selected LLM                                                 |

All functions are JWTâ€‘less and invoked via `supabase.functions.invoke()` from the frontend or by n8n.

---

## ğŸ¤– n8n Workflows

1. **Chat Handler** â€“ `/webhook/hhlm-chat` â†’ prepares context â†’ routes to provider â†’ streams result back
2. **Embedding Generator** â€“ `/webhook/generate-embeddings` â†’ fetches chunk batch â†’ calls embedding API â†’ upserts into `chunk_embeddings`

Import `n8n-workflows.json`, set environment variables, and **activate** each workflow.

---

## âš™ï¸ Configuration

### Environment (.env.local)

```env
VITE_SUPABASE_URL=https://<project>.supabase.co
VITE_SUPABASE_ANON_KEY=...
SUPABASE_SERVICE_ROLE_KEY=...

OLLAMA_BASE_URL=http://localhost:11434
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=AIza...
LLAMACLOUD_API_KEY=llx-...

N8N_WEBHOOK_BASE_URL=http://localhost:5678
N8N_API_KEY=...
```

### LLM Defaults (override per request)

| Provider | Chat Model        | Embed Model               | Temp |
| -------- | ----------------- | ------------------------- | ---- |
| Ollama   | `qwen3:8b-q4_K_M` | `nomic-embed-text:latest` | 0.3  |
| OpenAI   | `gpt-4`           | `text-embedding-3-small`  | 0.3  |
| Gemini   | `gemini-pro`      | `embedding-001`           | 0.3  |

---

## ğŸš€ Quick Start

```bash
# 1. Install deps
npm i && npm i -g supabase

# 2. Configure env & link project
cp .env.local.example .env.local
supabase link --project-ref <ref>

# 3. Provision database
supabase db push

# 4. Deploy edge functions
./deploy-functions.sh

# 5. Seed storage buckets & templates (optional)

# 6. Start n8n & Ollama
npx n8n  &  ollama serve &

# 7. Run dev frontend
npm run dev
```

Open [http://localhost:5173](http://localhost:5173) â†’ create notebook â†’ upload PDF â†’ chat & generate report.

---

## ğŸ§ª Testing

* **Supabase**: `supabase status`
* **Edge Log**: `supabase functions logs --tail`
* **Chat Webhook**:

  ```bash
  curl -X POST http://localhost:5678/webhook/hhlm-chat -H 'Content-Type: application/json' -d '{"sessionId":"test","message":"Hello"}'
  ```

---

## ğŸ“ˆ Monitoring & Scaling

| Layer     | Tip                                                                |
| --------- | ------------------------------------------------------------------ |
| DB        | Enable **pointâ€‘inâ€‘time recovery** and log **pg\_stat\_statements** |
| Functions | Use Supabase **Edge runâ€‘metrics** + Langfuse for LLM observability |
| n8n       | Persist executions, set retries, and add failure hooks             |
| LLMs      | Cache embeddings (Redis) and stream chat completions               |

---

## ğŸ›¡ï¸ Security Checklist

* [x] API keys stored as Supabase **secrets** (service role only)
* [x] RLS policies enforced (see `*.sql`)
* [x] Storage bucket ACL = private perâ€‘user
* [x] CORS `*` only for dev; tighten in prod

---

## ğŸ‘¥ Contributing

1. Fork & create feature branch (`git checkout -b feat/awesome`)
2. Run `npm run lint && npm run test`
3. Submit PR with context & screenshots

---

## ğŸ“œ License

MIT Â© 2025 CoralShades â€“ Built with â¤ï¸ in Melbourne
